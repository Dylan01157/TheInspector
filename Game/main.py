"""
Jeu d'enqu√™te interactif avec interface web (Flask)
-------------------------------------------------
Trois suspects (IA Gemma ou simulateurs) sont interrog√©s via une interface web.
Le joueur peut poser des questions, cliquer sur un suspect, et accuser l'un d'eux.
Si l'accusation est correcte, le meurtrier avoue. Sinon, la partie red√©marre avec un nouveau sc√©nario.
"""

from flask import Flask, render_template, request, jsonify
import random
import requests
import time

app = Flask(__name__)

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "gemma3:4b"

# ------------------ Trames de base ------------------
TRAMES = [
    {
        "context": "Un meurtre a eu lieu dans un manoir isol√© lors d'une temp√™te.",
        "metiers": ["chef cuisinier", "m√©decin", "peintre"],
    },
    {
        "context": "Une disparition myst√©rieuse dans un train de nuit.",
        "metiers": ["conducteur", "journaliste", "com√©dien"],
    },
    {
        "context": "Un crime dans une station de recherche polaire.",
        "metiers": ["scientifique", "technicien", "infirmier"],
    }
]

TRAME_INNOCENT = (
    "Tu es {name}, {age} ans, {metier}.\n"
    "Personnalit√©: {personnalite}.\n"
    "Alibi: {alibi}.\n"
    "Contexte: {context}\n"
    "Consignes de style :\n"
    "- Quand tu d√©cris tes actions, gestes ou √©motions, parle √† la 3·µâ personne.\n"
    "- Quand tu parles au joueur (dialogue), parle √† la 1 ≥·µâ personne.\n"
    "- Tu es suspect(e), mais innocent(e). R√©ponds comme ton personnage le ferait."
)

TRAME_MEURTRIER = (
    "Tu es {name}, {age} ans, {metier}.\n"
    "Personnalit√©: {personnalite}.\n"
    "Alibi: {alibi}.\n"
    "Contexte: {context}\n"
    "Consignes de style :\n"
    "- Quand tu d√©cris tes actions, gestes ou √©motions, parle √† la 3·µâ personne.\n"
    "- Quand tu parles au joueur (dialogue), parle √† la 1 ≥·µâ personne.\n"
    "- Tu es le MEURTRIER. Tu dois cacher ta culpabilit√© et rester cr√©dible."
)


# ------------------ Utilitaires ------------------
def call_ollama(prompt: str) -> str:
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False  # important: on veut une seule r√©ponse JSON
    }
    r = requests.post(OLLAMA_URL, json=payload, timeout=30)
    data = r.json()
    return data.get("response") or data.get("output", [{"content": "(aucune r√©ponse)"}])[0].get("content", "(aucune r√©ponse)")


def simulate_response(name, murderer, question):
    base = f"{name}: "
    if murderer:
        base += random.choice([
            "Je ne vois pas pourquoi je serais accus√©...",
            "C'est ridicule, je n'ai rien fait.",
            "Je pense que vous perdez votre temps."
        ])
    else:
        base += random.choice([
            "Je n'ai rien vu, j'√©tais ailleurs.",
            "Je ne connaissais pas la victime.",
            "Je vous jure, je n'ai rien fait."
        ])
    if "o√π" in question.lower():
        base += " J'√©tais dans un autre endroit au moment du crime."
    return base

# ------------------ Classe Agent ------------------
class Agent:
    def __init__(self, nom, prompt_initial, murderer=False, use_ollama=False):
        self.nom = nom
        self.prompt_initial = prompt_initial
        self.murderer = murderer
        self.use_ollama = use_ollama
        self.history = []

    def repondre(self, question):
        prompt = self.prompt_initial + "\n" + "\n".join(self.history[-6:]) + f"\nJoueur: {question}\n{self.nom}:"
        if self.use_ollama:
            try:
                response = call_ollama(prompt)
            except Exception as e:
                print("Erreur Ollama :", e)
                response = simulate_response(self.nom, self.murderer, question)
        else:
            response = simulate_response(self.nom, self.murderer, question)
        self.history.append(f"Joueur: {question}")
        self.history.append(f"{self.nom}: {response}")
        return response

# ------------------ G√©n√©ration d'un sc√©nario ------------------
def generer_scenario(use_ollama=False):
    t = random.choice(TRAMES)
    context = t['context']
    roles = random.sample(t['metiers'], 3)
    murderer_index = random.randint(0, 2)

    # --- G√©n√©ration de la victime ---
    victime_prenoms = ["Clara", "Luc", "√âlodie", "Martin", "Sophie", "Nicolas"]
    victime_noms = ["Morel", "Durand", "Petit", "Garcia", "Bernard", "Roux"]
    victime_metiers = ["journaliste", "commer√ßant", "professeur", "critique d‚Äôart", "chercheur", "photographe"]
    victime_nom = f"{random.choice(victime_prenoms)} {random.choice(victime_noms)}"
    victime_age = random.randint(28, 50)
    victime_metier = random.choice(victime_metiers)
    cause_mort = random.choice([
        "a √©t√© frapp√© √† la t√™te avec un objet lourd",
        "a √©t√© empoisonn√© pendant le d√Æner",
        "a √©t√© poignard√© dans le dos",
        "a √©t√© retrouv√© √©trangl√© dans le bureau",
        "a √©t√© d√©couvert mort dans la biblioth√®que, sans trace d‚Äôeffraction"
    ])

    # --- Lien entre la victime et les suspects ---
    relations_possibles = [
        "travaillait pour la victime depuis plusieurs ann√©es",
        "√©tait un ami proche de la victime",
        "avait eu une dispute r√©cente avec la victime",
        "devait de l'argent √† la victime",
        "√©tait souvent en d√©saccord avec la victime"
    ]

    persos = []
    presentation = (
        f"üïØÔ∏è Nouvelle enqu√™te :\n\n"
        f"{context}\n\n"
        f"La victime est **{victime_nom}**, {victime_age} ans, {victime_metier}. "
        f"Elle {cause_mort}.\n\n"
        f"Les suspects sont :\n"
    )

    for i, nom in enumerate(["Ariane", "Benoit", "Camille"]):
        metier = roles[i]
        age = random.randint(25, 50)
        personnalite = random.choice([
            "calme et observateur", "bavard et s√ªr de lui", "nerveux et curieux"
        ])
        relation = random.choice(relations_possibles)
        alibi = random.choice([
            "√©tait seul dans sa chambre", "travaillait tard", "√©tait dehors √† fumer"
        ])

        if i == murderer_index:
            prompt = TRAME_MEURTRIER.format(
                name=nom, age=age, metier=metier, personnalite=personnalite,
                alibi=alibi, context=f"{context}\nLa victime √©tait {victime_nom}, {victime_metier}. Tu {relation}."
            )
            murderer = True
        else:
            prompt = TRAME_INNOCENT.format(
                name=nom, age=age, metier=metier, personnalite=personnalite,
                alibi=alibi, context=f"{context}\nLa victime √©tait {victime_nom}, {victime_metier}. Tu {relation}."
            )
            murderer = False

        persos.append(Agent(nom, prompt, murderer, use_ollama))
        presentation += f"‚Ä¢ {nom}, {age} ans, {metier}, {personnalite} ‚Äî {relation}.\n"

    presentation += "\n√Ä vous de poser vos questions pour d√©couvrir la v√©rit√©‚Ä¶"

    return persos, murderer_index, presentation



# ------------------ Variables globales ------------------
agents = []
murderer_index = None
context_actuel = None
use_ollama = True
notes = {}  # cl√© = nom du suspect ou 'victime', valeur = texte

# ------------------ Routes Flask ------------------
@app.route('/')
def index():
    global agents, murderer_index, context_actuel
    agents, murderer_index, context_actuel = generer_scenario(use_ollama)
    noms = [a.nom for a in agents]
    return render_template('index.html', suspects=noms, context=context_actuel)

@app.route('/note', methods=['POST'])
def add_note():
    data = request.get_json()
    sujet = data.get('sujet')  # nom du suspect ou 'victime'
    texte = data.get('texte')
    if sujet:
        notes[sujet] = texte
    return jsonify({"status": "ok", "notes": notes})

# R√©cup√©rer toutes les notes
@app.route('/notes', methods=['GET'])
def get_notes():
    return jsonify({"notes": notes})

@app.route('/question', methods=['POST'])
def question():
    data = request.get_json()
    nom = data.get('nom')
    question = data.get('question')
    agent = next((a for a in agents if a.nom == nom), None)
    if not agent:
        return jsonify({"reponse": "Suspect inconnu."})
    reponse = agent.repondre(question)
    return jsonify({"reponse": reponse})

@app.route('/accuser', methods=['POST'])
def accuser():
    data = request.get_json()
    nom = data.get('nom')
    global murderer_index, agents
    vrai_nom = agents[murderer_index].nom
    if nom == vrai_nom:
        return jsonify({"resultat": "gagn√©", "message": f"Bravo ! {nom} √©tait bien le meurtrier et il avoue tout !"})
    else:
        agents[:], murderer_index, context = generer_scenario(use_ollama)
        return jsonify({"resultat": "perdu", "message": f"Non, {nom} √©tait innocent... Le jeu recommence avec une nouvelle enqu√™te !"})

if __name__ == '__main__':
    app.run(debug=True)